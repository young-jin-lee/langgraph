{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4c3bec-f9fa-4539-8234-7071613ec3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3c729-3aaa-47e1-9043-a92564e5a123",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Invoking / Streaming funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ce43a28-eed5-4021-ad58-5d65dbcdf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from typing import Any, Dict, List, Callable, Optional\n",
    "\n",
    "def stream_graph(\n",
    "    graph: CompiledStateGraph,\n",
    "    inputs: dict,\n",
    "    config: RunnableConfig,\n",
    "    node_names: List[str] = [],\n",
    "    callback: Callable = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    LangGraph의 실행 결과를 스트리밍하여 출력하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        graph (CompiledStateGraph): 실행할 컴파일된 LangGraph 객체\n",
    "        inputs (dict): 그래프에 전달할 입력값 딕셔너리\n",
    "        config (RunnableConfig): 실행 설정\n",
    "        node_names (List[str], optional): 출력할 노드 이름 목록. 기본값은 빈 리스트\n",
    "        callback (Callable, optional): 각 청크 처리를 위한 콜백 함수. 기본값은 None\n",
    "            콜백 함수는 {\"node\": str, \"content\": str} 형태의 딕셔너리를 인자로 받습니다.\n",
    "\n",
    "    Returns:\n",
    "        None: 함수는 스트리밍 결과를 출력만 하고 반환값은 없습니다.\n",
    "    \"\"\"\n",
    "    prev_node = \"\"\n",
    "    for chunk_msg, metadata in graph.stream(inputs, config, stream_mode=\"messages\"):\n",
    "        curr_node = metadata[\"langgraph_node\"]\n",
    "\n",
    "        # node_names가 비어있거나 현재 노드가 node_names에 있는 경우에만 처리\n",
    "        if not node_names or curr_node in node_names:\n",
    "            # 콜백 함수가 있는 경우 실행\n",
    "            if callback:\n",
    "                callback({\"node\": curr_node, \"content\": chunk_msg.content})\n",
    "            # 콜백이 없는 경우 기본 출력\n",
    "            else:\n",
    "                # 노드가 변경된 경우에만 구분선 출력\n",
    "                if curr_node != prev_node:\n",
    "                    print(\"\\n\" + \"=\" * 50)\n",
    "                    print(f\"🔄 Node: \\033[1;36m{curr_node}\\033[0m 🔄\")\n",
    "                    print(\"- \" * 25)\n",
    "\n",
    "                if isinstance(chunk_msg, HumanMessage):\n",
    "                    print(\"🧑‍💬 \\033[1;35m[Human Message]\\033[0m\", flush=True)\n",
    "                elif isinstance(chunk_msg, AIMessage):\n",
    "                    print(\"🤖 \\033[1;34m[AI Message]\\033[0m\", flush=True)\n",
    "                elif isinstance(chunk_msg, SystemMessage):\n",
    "                    print(\"⚙️  \\033[1;33m[System Message]\\033[0m\", flush=True)\n",
    "                elif isinstance(chunk_msg, ToolMessage):\n",
    "                    print(\"🛠️ \\033[1;32m[Tool Message]\\033[0m\", flush=True)\n",
    "                else:\n",
    "                    print(\"📦 \\033[1;90m[Other Message]\\033[0m\", flush=True)\n",
    "                    \n",
    "                print(chunk_msg.content, end=\"\", flush=True)\n",
    "\n",
    "            prev_node = curr_node\n",
    "\n",
    "\n",
    "def invoke_graph(\n",
    "    graph: CompiledStateGraph,\n",
    "    inputs: dict,\n",
    "    config: RunnableConfig,\n",
    "    node_names: List[str] = [],\n",
    "    callback: Callable = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    LangGraph 앱의 실행 결과를 예쁘게 스트리밍하여 출력하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        graph (CompiledStateGraph): 실행할 컴파일된 LangGraph 객체\n",
    "        inputs (dict): 그래프에 전달할 입력값 딕셔너리\n",
    "        config (RunnableConfig): 실행 설정\n",
    "        node_names (List[str], optional): 출력할 노드 이름 목록. 기본값은 빈 리스트\n",
    "        callback (Callable, optional): 각 청크 처리를 위한 콜백 함수. 기본값은 None\n",
    "            콜백 함수는 {\"node\": str, \"content\": str} 형태의 딕셔너리를 인자로 받습니다.\n",
    "\n",
    "    Returns:\n",
    "        None: 함수는 스트리밍 결과를 출력만 하고 반환값은 없습니다.\n",
    "    \"\"\"\n",
    "\n",
    "    def format_namespace(namespace):\n",
    "        return namespace[-1].split(\":\")[0] if len(namespace) > 0 else \"root graph\"\n",
    "\n",
    "    # subgraphs=True 를 통해 서브그래프의 출력도 포함\n",
    "    for namespace, chunk in graph.stream(\n",
    "        inputs, config, stream_mode=\"updates\", subgraphs=True\n",
    "    ):\n",
    "        for node_name, node_chunk in chunk.items():\n",
    "            # node_names가 비어있지 않은 경우에만 필터링\n",
    "            if len(node_names) > 0 and node_name not in node_names:\n",
    "                continue\n",
    "\n",
    "            # 콜백 함수가 있는 경우 실행\n",
    "            if callback is not None:\n",
    "                callback({\"node\": node_name, \"content\": node_chunk})\n",
    "            # 콜백이 없는 경우 기본 출력\n",
    "            else:\n",
    "                print(\"\\n\" + \"=\" * 50)\n",
    "                formatted_namespace = format_namespace(namespace)\n",
    "                if formatted_namespace == \"root graph\":\n",
    "                    print(f\"🔄 Node: \\033[1;36m{node_name}\\033[0m 🔄\")\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"🔄 Node: \\033[1;36m{node_name}\\033[0m in [\\033[1;33m{formatted_namespace}\\033[0m] 🔄\"\n",
    "                    )\n",
    "                print(\"- \" * 25)\n",
    "\n",
    "                # 노드의 청크 데이터 출력\n",
    "                if isinstance(node_chunk, dict):\n",
    "                    for k, v in node_chunk.items():\n",
    "                        if isinstance(v, BaseMessage):\n",
    "                            if isinstance(v, HumanMessage):\n",
    "                                print(\"🧑‍💬 \\033[1;35m[Human Message]\\033[0m\")\n",
    "                            elif isinstance(v, AIMessage):\n",
    "                                print(\"🤖 \\033[1;34m[AI Message]\\033[0m\")\n",
    "                            elif isinstance(v, SystemMessage):\n",
    "                                print(\"⚙️  \\033[1;33m[System Message]\\033[0m\")\n",
    "                            elif isinstance(v, ToolMessage):\n",
    "                                print(\"🛠️ \\033[1;32m[Tool Message]\\033[0m\")\n",
    "                            else:\n",
    "                                print(\"📦 \\033[1;90m[Other Message]\\033[0m\")\n",
    "                            v.pretty_print()\n",
    "                        elif isinstance(v, list):\n",
    "                            for list_item in v:\n",
    "                                if isinstance(list_item, BaseMessage):\n",
    "                                    list_item.pretty_print()\n",
    "                                else:\n",
    "                                    print(list_item)\n",
    "                        elif isinstance(v, dict):\n",
    "                            for node_chunk_key, node_chunk_value in node_chunk.items():\n",
    "                                print(f\"{node_chunk_key}:\\n{node_chunk_value}\")\n",
    "                        else:\n",
    "                            print(f\"\\033[1;32m{k}\\033[0m:\\n{v}\")\n",
    "                else:\n",
    "                    if node_chunk is not None:\n",
    "                        for item in node_chunk:\n",
    "                            print(item)\n",
    "                print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795ffa5-caaf-4ecd-af80-a8c4502ea359",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Doc Evaluating funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a76980f7-2b30-4955-9fd7-ebaca23eb76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class grade(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Return 'yes' if the retrieved document is relevant to the question, otherwise 'no'.\"\n",
    "    )\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming = True)\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template = \"\"\"\n",
    "        You are a grader assessing relevance of a retrieved document to a user question \\n\n",
    "        Here is the question: {question} \\n\\n\n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        If the document contains any keywords or semantic meanings related to the user question, grade it as relevant \\n\n",
    "        Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question. \"\"\",\n",
    "        input_variables = [\"question\", \"context\"],\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    last_message = messages[-1]\n",
    "    retrieved_docs = last_message.content ### ASSUME that the last message is the retrieved_docs.\n",
    "\n",
    "    question = messages[0].content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\":question, \"context\":retrieved_docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "    \n",
    "    if score == \"yes\":\n",
    "        print(\"=== [DECISION: DOCS RELEVENT] ===\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"=== [DECISION: DOCS IRRELEVENT] ===\")\n",
    "        return \"rewrite\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e106eb3-aca6-40de-aabb-b9a58788305a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PDF Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5e47f3db-54e7-4cbf-84a3-3dbce4ecf887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/RAGwithLangChain.pdf\n"
     ]
    }
   ],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/RAGwithLangChain.pdf\"]).create_chain()\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28a6321e-e3c3-46b4-a9fc-5eca4474a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever = pdf_retriever,\n",
    "    name = \"pdf_retriever\",\n",
    "    description = \"\"\"Search and return information about SPRI AI Brief PDF file.  \n",
    "        It contains useful information on recent AI trends. \n",
    "        The document is published in Dec 2023.\"\"\", # LLM decides upon which tool to use based on this description.\n",
    "    document_prompt = PromptTemplate.from_template(\n",
    "      \"\"\"<document>\n",
    "            <content>\n",
    "                {page_content}\n",
    "            </content>\n",
    "            <metadata>\n",
    "                <source>\n",
    "                    {source}\n",
    "                </source>\n",
    "                <page>\n",
    "                    {page}\n",
    "                </page>\n",
    "            </metadata>\n",
    "        </document>\"\"\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe991f-2f9e-45ba-8883-6bcc315aa738",
   "metadata": {},
   "source": [
    "## State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "23892cbd-6710-4829-8e34-4a57a7ce57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    # messages: Annotated[list, add_messages] # pre-built in MessagesState\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58ead0-8bd2-4735-823c-98fb0e9f517a",
   "metadata": {},
   "source": [
    "## Node definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dd53a6ad-ccee-48fe-b061-148141db31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain import hub\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "def agent(state: AgentState) -> AgentState:\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0, streaming = True, model = MODEL_NAME)\n",
    "\n",
    "    llm_with_tools = llm.bind_tools([retriever_tool])\n",
    "\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def rewrite(state: AgentState) -> AgentState:\n",
    "    print(\"=== [REWRITE QUERY] ===\")\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"\\n\n",
    "                        Look at the input and try to reason about the underlying semantic intention or meaing \\n\n",
    "                        \\n ----------- \\n\n",
    "                        {question}\n",
    "                        \\n ----------- \\n\n",
    "                        Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "    response = model.invoke(msg)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def generate(state):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = messages[-1].content\n",
    "\n",
    "    prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "    llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0, streaming=True)\n",
    "\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = rag_chain.invoke({\"context\":docs, \"question\": question})\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=response)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738883ef-ef11-4025-a459-1a2b8e5283d3",
   "metadata": {},
   "source": [
    "## Graph Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "467a60bc-4621-4ee9-81a7-30b1206d48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Add Nodes\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "# Add Edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\", # from \"agent\"\n",
    "    tools_condition, # call tools_condition\n",
    "    {\n",
    "        \"tools\": \"retrieve\", # If tools_condition returns \"tools\", go to \"retrieve\"\n",
    "        \"END\": END, # If tools_condition return \"END\", go to END\n",
    "        \"__end__\": END, # when the branch node is internally terminated\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\", # from retrieve\n",
    "    grade_documents, # call grade_documents\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "42247c39-e161-4b14-9abb-af65a4524d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.visualize import visualize_graph\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "43eb3d95-cfd1-4395-9b0a-5ab37c38d83d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  pdf_retriever (call_8FTvB6Q6wC8itUP6W88PCC6k)\n",
      " Call ID: call_8FTvB6Q6wC8itUP6W88PCC6k\n",
      "  Args:\n",
      "    query: RAG\n",
      "  pdf_retriever (call_d9KYkDBUc7Z7Csang9W9IHuC)\n",
      " Call ID: call_d9KYkDBUc7Z7Csang9W9IHuC\n",
      "  Args:\n",
      "    query: Langchain\n",
      "==================================================\n",
      "=== [DECISION: DOCS RELEVENT] ===\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mretrieve\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: pdf_retriever\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                CLIP\n",
      "Comparative Analysis of RAG\n",
      "Frameworks\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    7\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                PART\n",
      "RAG with LangChain\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    1\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Comparative analysis of RAG Frameworks\n",
      "Chain\n",
      "Vectorstore\n",
      "Memory\n",
      "Document\n",
      "loader\n",
      "🦙\n",
      "🦜🔗\n",
      "Tool\n",
      "Embedding\n",
      "model\n",
      "Graph\n",
      "LM\n",
      "Agent\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    8\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                RAG를 활용한 완성도 높은 LLM 서비스 구축\n",
      "With Langchain & LLamaIndex\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    0\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                CLIP\n",
      "Recap\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    9\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Recap\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "prompt=\"given\n",
      "embed_model=bge\n",
      "chunk_size=128 context...\"\n",
      "llm_model=mistral\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "시급이며 교통비가 별도 지급된\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    10\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "시급이며 교통비가 별도 지급된\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "chunk2:\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    3\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "La시급n이며 교g통비가C 별도 지h급된 ain\n",
      "🦜\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    5\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Recap\n",
      "LangGraph\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    13\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "Lla시급m이며 교통a비가 별I도n 지급된dex\n",
      "🦙\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    4\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: pdf_retriever\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                CLIP\n",
      "Introduction to LangChain\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    2\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                PART\n",
      "RAG with LangChain\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    1\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "Chain Vectorstore\n",
      "Document\n",
      "Memory\n",
      "loader\n",
      "🦜🔗\n",
      "Embedding\n",
      "Tool\n",
      "model\n",
      "Graph LM\n",
      "Agent\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    6\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Recap\n",
      "LangGraph\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    13\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                RAG를 활용한 완성도 높은 LLM 서비스 구축\n",
      "With Langchain & LLamaIndex\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    0\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "Lla시급m이며 교통a비가 별I도n 지급된dex\n",
      "🦙\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    4\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "La시급n이며 교g통비가C 별도 지h급된 ain\n",
      "🦜\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    5\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "시급이며 교통비가 별도 지급된\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "chunk2:\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    3\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Recap\n",
      "Chain\n",
      "Vectorstore\n",
      "Memory\n",
      "Document\n",
      "loader\n",
      "🦙\n",
      "🦜🔗\n",
      "Tool\n",
      "Embedding\n",
      "model\n",
      "Graph\n",
      "LM\n",
      "Agent\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    11\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                CLIP\n",
      "Recap\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    9\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "RAG( Retrieval-Augmented Generation)와 LangChain의 차이는 RAG가 정보 검색과 생성 모델을 결합하여 질문에 대한 답변을 생성하는 반면, LangChain은 다양한 도구와 메모리 기능을 통합하여 복잡한 작업을 수행할 수 있는 프레임워크라는 점입니다. RAG는 주로 정보 검색에 중점을 두고, LangChain은 다양한 구성 요소를 통해 더 유연한 애플리케이션을 지원합니다.\n",
      "\n",
      "**Source**\n",
      "- data/RAGwithLangChain.pdf (page 1)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": \"4\"})\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"RAG와 Langchain의 차이\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    invoke_graph(app, inputs, config)\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97122e2d-8158-435d-8d2e-ce97a687810a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "RAG와 Langchain의 차이\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  pdf_retriever (call_hiLwf1b5FqtuBxp21f4Ygn1v)\n",
      " Call ID: call_hiLwf1b5FqtuBxp21f4Ygn1v\n",
      "  Args:\n",
      "    query: RAG\n",
      "  pdf_retriever (call_xOOLu5iTt9FT3h9KpXbPtlPk)\n",
      " Call ID: call_xOOLu5iTt9FT3h9KpXbPtlPk\n",
      "  Args:\n",
      "    query: Langchain\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: pdf_retriever\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                CLIP\n",
      "Comparative Analysis of RAG\n",
      "Frameworks\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    7\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                PART\n",
      "RAG with LangChain\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    1\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Comparative analysis of RAG Frameworks\n",
      "Chain\n",
      "Vectorstore\n",
      "Memory\n",
      "Document\n",
      "loader\n",
      "🦙\n",
      "🦜🔗\n",
      "Tool\n",
      "Embedding\n",
      "model\n",
      "Graph\n",
      "LM\n",
      "Agent\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    8\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                RAG를 활용한 완성도 높은 LLM 서비스 구축\n",
      "With Langchain & LLamaIndex\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    0\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                CLIP\n",
      "Recap\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    9\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Recap\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "prompt=\"given\n",
      "embed_model=bge\n",
      "chunk_size=128 context...\"\n",
      "llm_model=mistral\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "시급이며 교통비가 별도 지급된\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    10\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "시급이며 교통비가 별도 지급된\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "chunk2:\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    3\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "La시급n이며 교g통비가C 별도 지h급된 ain\n",
      "🦜\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    5\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Recap\n",
      "LangGraph\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    13\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "Lla시급m이며 교통a비가 별I도n 지급된dex\n",
      "🦙\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    4\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: pdf_retriever\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                CLIP\n",
      "Introduction to LangChain\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    2\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                PART\n",
      "RAG with LangChain\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    1\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "Chain Vectorstore\n",
      "Document\n",
      "Memory\n",
      "loader\n",
      "🦜🔗\n",
      "Embedding\n",
      "Tool\n",
      "model\n",
      "Graph LM\n",
      "Agent\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    6\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Recap\n",
      "LangGraph\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    13\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                RAG를 활용한 완성도 높은 LLM 서비스 구축\n",
      "With Langchain & LLamaIndex\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    0\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "Lla시급m이며 교통a비가 별I도n 지급된dex\n",
      "🦙\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    4\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "La시급n이며 교g통비가C 별도 지h급된 ain\n",
      "🦜\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    5\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Introduction to LangChain\n",
      "RAG Pipeline\n",
      "User query\n",
      "2024년 최저시급은 얼마야?\n",
      "2024년 한국의 최저임금은 9860원입니다.\n",
      "Indexing Retrieval Generation\n",
      "chunks Relevant 다음 주어지는 문서를 참고해\n",
      "documents chunk1: \"임금은 2024년 최저\n",
      "embedding documents user question에 대한 답변을\n",
      "시급이며 교통비가 별도 지급된\n",
      "생성하시오\n",
      "다\"\n",
      "chunk1:\n",
      "chunk2: \"2024년 1월부터 최\n",
      "chunk2:\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    3\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                Recap\n",
      "Chain\n",
      "Vectorstore\n",
      "Memory\n",
      "Document\n",
      "loader\n",
      "🦙\n",
      "🦜🔗\n",
      "Tool\n",
      "Embedding\n",
      "model\n",
      "Graph\n",
      "LM\n",
      "Agent\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    11\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "\n",
      "<document>\n",
      "            <content>\n",
      "                CLIP\n",
      "Recap\n",
      "            </content>\n",
      "            <metadata>\n",
      "                <source>\n",
      "                    data/RAGwithLangChain.pdf\n",
      "                </source>\n",
      "                <page>\n",
      "                    9\n",
      "                </page>\n",
      "            </metadata>\n",
      "        </document>\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "RAG( Retrieval-Augmented Generation)와 LangChain의 차이는 RAG가 정보 검색과 생성 모델을 결합하여 질문에 대한 답변을 생성하는 반면, LangChain은 다양한 도구와 메모리 기능을 통합하여 복잡한 언어 모델 애플리케이션을 구축하는 프레임워크라는 점입니다.\n",
      "\n",
      "**Source**\n",
      "- data/RAGwithLangChain.pdf (page 1)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "RAG와 Langchain의 차이\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "RAG( Retrieval-Augmented Generation)와 LangChain의 차이는 다음과 같습니다:\n",
      "\n",
      "1. **RAG (Retrieval-Augmented Generation)**:\n",
      "   - RAG는 정보 검색과 생성 모델을 결합하여 사용자의 질문에 대한 답변을 생성하는 방법론입니다.\n",
      "   - 이 접근 방식은 대량의 데이터에서 관련 정보를 검색하고, 이를 바탕으로 자연어로 응답을 생성합니다.\n",
      "   - RAG는 주로 대화형 AI 및 질문 응답 시스템에서 사용됩니다.\n",
      "\n",
      "2. **LangChain**:\n",
      "   - LangChain은 다양한 도구와 메모리 기능을 통합하여 복잡한 언어 모델 애플리케이션을 구축하는 프레임워크입니다.\n",
      "   - 이 프레임워크는 체인, 벡터 저장소, 메모리, 문서 로더 등 다양한 구성 요소를 활용하여 언어 모델의 기능을 확장합니다.\n",
      "   - LangChain은 RAG와 같은 기술을 포함할 수 있지만, 더 넓은 범위의 언어 모델 애플리케이션을 지원하는 데 중점을 둡니다.\n",
      "\n",
      "결론적으로, RAG는 정보 검색과 생성의 결합에 중점을 두고, LangChain은 다양한 도구와 기능을 통합하여 언어 모델을 활용하는 프레임워크입니다.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "RAG와 Langchain의 차이\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "RAG( Retrieval-Augmented Generation)와 LangChain의 차이는 다음과 같습니다:\n",
      "\n",
      "1. **RAG (Retrieval-Augmented Generation)**:\n",
      "   - RAG는 정보 검색과 생성 모델을 결합하여 사용자의 질문에 대한 답변을 생성하는 방법론입니다.\n",
      "   - 이 접근 방식은 대량의 데이터에서 관련 정보를 검색하고, 이를 바탕으로 자연어로 응답을 생성합니다.\n",
      "   - RAG는 주로 대화형 AI 및 질문 응답 시스템에서 사용됩니다.\n",
      "\n",
      "2. **LangChain**:\n",
      "   - LangChain은 다양한 도구와 메모리 기능을 통합하여 복잡한 언어 모델 애플리케이션을 구축하는 프레임워크입니다.\n",
      "   - 이 프레임워크는 체인, 벡터 저장소, 메모리, 문서 로더 등 다양한 구성 요소를 활용하여 언어 모델의 기능을 확장합니다.\n",
      "   - LangChain은 RAG와 같은 기술을 포함할 수 있지만, 더 넓은 범위의 언어 모델 애플리케이션을 지원하는 데 중점을 둡니다.\n",
      "\n",
      "결론적으로, RAG는 정보 검색과 생성의 결합에 중점을 두고, LangChain은 다양한 도구와 기능을 통합하여 언어 모델을 활용하는 프레임워크입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "messages = [HumanMessage(content=\"RAG와 Langchain의 차이\")]\n",
    "messages = app.invoke({\"messages\": messages}, config = config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2a8d8b9a-e43d-45ed-be0e-b41f5231e351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mretrieve\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "{\"🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "binary🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "_score🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "\":\"🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "no🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "\"}🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "🤖 \u001b[1;34m[AI Message]\u001b[0m\n",
      "=== [DECISION: DOCS IRRELEVENT] ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ToolMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      2\u001b[39m inputs = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      4\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m이영진이 누구야?\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m     ]\n\u001b[32m      6\u001b[39m }\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mstream_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mretrieve\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrewrite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenerate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GraphRecursionError \u001b[38;5;28;01mas\u001b[39;00m recursion_error:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGraphRecursionError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecursion_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mstream_graph\u001b[39m\u001b[34m(graph, inputs, config, node_names, callback)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk_msg, SystemMessage):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚙️  \u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[33m[1;33m[System Message]\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[33m[0m\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk_msg, \u001b[43mToolMessage\u001b[49m):\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🛠️ \u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[33m[1;32m[Tool Message]\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[33m[0m\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'ToolMessage' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"이영진이 누구야?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    stream_graph(app, inputs, config, [\"agent\", \"retrieve\", \"rewrite\", \"generate\"])\n",
    "    \n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdb598b4-c743-4aa0-8985-b597763acc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: {'agent': {'messages': [AIMessage(content='RAG는 Retrieval-Augmented Generation의 약자로, 정보 검색과 생성 모델을 결합하여 사용자 쿼리에 대한 답변을 생성하는 시스템입니다. 이 시스템은 사용자의 질문에 대해 관련 정보를 검색하고, 이를 바탕으로 자연어로 응답을 생성합니다. \\n\\n**출처**\\n- data/RAGwithLangChain.pdf (페이지 10)', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'service_tier': 'default'}, id='run--1d6647b5-10c1-46e8-825c-8a7ac205a39f-0')]}}\n",
      "Node: agent\n"
     ]
    }
   ],
   "source": [
    "for step in app.stream(user_input, config=config):\n",
    "    print(\"step:\", step)\n",
    "    for node_name, output in step.items():\n",
    "        print(\"Node:\", node_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce7a0c1-31de-4dcd-ba53-c8e876d709b5",
   "metadata": {},
   "source": [
    "### Where RAG is unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d763994-b35f-4452-9161-7c4d99401130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "대한민국의 수도는 서울입니다."
     ]
    }
   ],
   "source": [
    "# 문서 검색이 불가능한 질문 예시\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"대한민국의 수도는?\"),\n",
    "    ]\n",
    "}\n",
    "try:\n",
    "    stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066e889-412c-4a94-b6f0-d1b2746dd5d5",
   "metadata": {},
   "source": [
    "### Where it is impossible to get info from the docs using RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cfe02cf-adb5-4ad7-a682-f0157f3bfcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "죄송하지만, 현재로서는 귀하의 이름을 알 수 있는 정보가 없습니다. 이름을 알려주시면 그에 맞춰 대화할 수 있습니다!"
     ]
    }
   ],
   "source": [
    "# 문서 검색이 불가능한 질문 예시\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"내 이름을 알려줘\"),\n",
    "    ]\n",
    "}\n",
    "try:\n",
    "    stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b7c6a-6f73-4f84-abf9-5ee3f2c9143a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
